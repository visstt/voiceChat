import { useState, useRef, useCallback, useEffect } from "react";
import axios from "axios";

export { useCreateChat } from "./useCreateChat";
export { useChats } from "./useChats";
export { useDeleteChat } from "./useDeleteChat";
export { useChatMessages } from "./useChatMessages";
export { useSendMessage, useMessageStatus } from "./useSendMessage";
export type { ChatData } from "./useChats";
export type { Message, ChatWithMessages, UIMessage } from "./useChatMessages";
export type { MessageStatus } from "./useSendMessage";

const API_BASE_URL =
  import.meta.env.VITE_API_BASE_URL || "http://localhost:3000";

// –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
interface ClonedAudioData {
  id: number;
  originalUrl: string;
  clonedUrl?: string;
  voiceId: string;
  status: string;
  createdAt: string;
  updatedAt: string;
}

interface ChatResponse {
  id: number;
  question: string;
  audioUrl: string;
}

// –•—É–∫ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ –Ω–∞ —Å–µ—Ä–≤–µ—Ä
export const useUploadAudio = () => {
  const [isUploading, setIsUploading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const uploadAudio = async (audioBlob: Blob): Promise<number | null> => {
    try {
      setIsUploading(true);
      setError(null);

      const formData = new FormData();
      formData.append("file", audioBlob, "recording.wav");

      const response = await axios.post(
        `${API_BASE_URL}/audio/upload`,
        formData,
        {
          headers: {
            "Content-Type": "multipart/form-data",
          },
        }
      );

      const uploadResult = response.data;
      return uploadResult.id;
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : "Upload failed";
      setError(errorMessage);
      return null;
    } finally {
      setIsUploading(false);
    }
  };

  return { uploadAudio, isUploading, error };
};

// –•—É–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
export const useAudioStatus = () => {
  const [isProcessing, setIsProcessing] = useState(false);
  const [clonedAudioData, setClonedAudioData] =
    useState<ClonedAudioData | null>(null);
  const [error, setError] = useState<string | null>(null);

  const pollAudioStatus = async (
    id: number,
    onComplete?: (data: ClonedAudioData) => void
  ): Promise<void> => {
    try {
      setIsProcessing(true);
      setError(null);

      const checkStatus = async (): Promise<void> => {
        const response = await axios.get(`${API_BASE_URL}/audio/status/${id}`);
        const data = response.data;

        if (data.status === "completed") {
          setClonedAudioData(data);
          setIsProcessing(false);
          console.log(
            "‚è≥ Waiting 25 seconds for voice responses to be generated..."
          );

          // –í—ã–∑—ã–≤–∞–µ–º callback –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
          if (onComplete) {
            setTimeout(() => {
              onComplete(data);
            }, 25000);
          }
        } else if (data.status === "failed") {
          throw new Error("Voice cloning failed");
        } else {
          // –ï—Å–ª–∏ –µ—â–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–Ω–æ–≤–∞ —á–µ—Ä–µ–∑ 2 —Å–µ–∫—É–Ω–¥—ã
          setTimeout(checkStatus, 2000);
        }
      };

      await checkStatus();
    } catch (err) {
      const errorMessage =
        err instanceof Error ? err.message : "Processing failed";
      setError(errorMessage);
      setIsProcessing(false);
    }
  };

  return { pollAudioStatus, isProcessing, clonedAudioData, error };
};

// –•—É–∫ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≥–æ—Ç–æ–≤—ã—Ö –≥–æ–ª–æ—Å–æ–≤—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
export const useChatResponses = () => {
  const [isLoadingResponses, setIsLoadingResponses] = useState(false);
  const [chatResponses, setChatResponses] = useState<ChatResponse[]>([]);
  const [error, setError] = useState<string | null>(null);

  const loadChatResponses = async (voiceId: string): Promise<void> => {
    try {
      console.log(`üîÑ Loading chat responses for voiceId: ${voiceId}`);

      setIsLoadingResponses(true);
      setError(null);

      const response = await axios.get(
        `${API_BASE_URL}/audio/chat-responses?voiceId=${voiceId}`,
        {
          headers: {
            Accept: "application/json",
          },
        }
      );

      const responses = response.data;
      console.log(
        `üì• Received ${
          Array.isArray(responses) ? responses.length : 0
        } responses`
      );

      if (responses && Array.isArray(responses) && responses.length > 0) {
        console.log(
          `‚úÖ Successfully loaded ${responses.length} chat responses`
        );
        responses.forEach((item: ChatResponse, index: number) => {
          console.log(`   ${index + 1}. "${item.question}" (ID: ${item.id})`);
        });
        setChatResponses(responses);
      } else {
        console.log(`‚ö†Ô∏è No responses available yet`);
        setChatResponses([]);
      }
    } catch (err) {
      console.log(`üí• Error loading responses:`, err);
      const errorMessage =
        err instanceof Error ? err.message : "Failed to load chat responses";
      setError(errorMessage);
    } finally {
      setIsLoadingResponses(false);
    }
  };

  const clearResponses = () => {
    setChatResponses([]);
    setError(null);
  };

  const setLoadingState = (loading: boolean) => {
    setIsLoadingResponses(loading);
  };

  return {
    loadChatResponses,
    clearResponses,
    setLoadingState,
    isLoadingResponses,
    chatResponses,
    error,
  };
};

// –•—É–∫ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ
export const useAudioPlayer = () => {
  const [currentlyPlaying, setCurrentlyPlaying] = useState<number | null>(null);
  const [currentAudio, setCurrentAudio] = useState<HTMLAudioElement | null>(
    null
  );
  const [error, setError] = useState<string | null>(null);

  const stopPlaying = () => {
    if (currentAudio) {
      currentAudio.pause();
      currentAudio.currentTime = 0;
      setCurrentAudio(null);
    }
    setCurrentlyPlaying(null);
  };

  const playChatResponse = (responseId: number, audioUrl: string): void => {
    // –ï—Å–ª–∏ —É–∂–µ –∏–≥—Ä–∞–µ—Ç —ç—Ç–æ –∂–µ –∞—É–¥–∏–æ - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º
    if (currentlyPlaying === responseId) {
      stopPlaying();
      return;
    }

    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å
    if (currentAudio) {
      stopPlaying();
    }

    try {
      const audio = new Audio(audioUrl);
      setCurrentAudio(audio);

      audio.onplay = () => {
        setCurrentlyPlaying(responseId);
      };

      audio.onended = () => {
        setCurrentlyPlaying(null);
        setCurrentAudio(null);
      };

      audio.onerror = () => {
        setCurrentlyPlaying(null);
        setCurrentAudio(null);
        setError("Failed to play chat response");
      };

      // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º CORS —Ä–µ–∂–∏–º
      audio.crossOrigin = "anonymous";

      audio.play().catch(() => {
        setCurrentlyPlaying(null);
        setCurrentAudio(null);

        // Fallback —á–µ—Ä–µ–∑ fetch
        fetch(audioUrl)
          .then((response) => response.blob())
          .then((blob) => {
            const blobUrl = URL.createObjectURL(blob);
            const newAudio = new Audio(blobUrl);
            setCurrentAudio(newAudio);

            newAudio.onplay = () => setCurrentlyPlaying(responseId);
            newAudio.onended = () => {
              setCurrentlyPlaying(null);
              setCurrentAudio(null);
            };
            newAudio.play().catch((fallbackErr) => {
              setCurrentlyPlaying(null);
              setCurrentAudio(null);
              setError(`Failed to play chat response: ${fallbackErr.message}`);
            });
          })
          .catch((fetchErr) => {
            setCurrentlyPlaying(null);
            setCurrentAudio(null);
            setError(`Failed to load chat response audio: ${fetchErr.message}`);
          });
      });
    } catch {
      setCurrentlyPlaying(null);
      setCurrentAudio(null);
      setError("Failed to create audio player for chat response");
    }
  };

  return { playChatResponse, stopPlaying, currentlyPlaying, error };
};

// –•—É–∫ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ
interface UseAudioVisualizationOptions {
  canvasRef: React.RefObject<HTMLCanvasElement | null>;
  onRecordingStop?: (audioBlob: Blob) => void;
}

interface UseAudioVisualizationReturn {
  startVisualization: () => Promise<boolean>;
  stopVisualization: () => void;
  isAnimating: boolean;
}

export const useAudioVisualization = ({
  canvasRef,
  onRecordingStop,
}: UseAudioVisualizationOptions): UseAudioVisualizationReturn => {
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const animationIdRef = useRef<number | null>(null);
  const isAnimatingRef = useRef<boolean>(false);

  // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∞–Ω–∏–º–∞—Ü–∏–∏
  const stopAnimation = useCallback(() => {
    isAnimatingRef.current = false;
    if (animationIdRef.current) {
      cancelAnimationFrame(animationIdRef.current);
      animationIdRef.current = null;
    }

    // –û—á–∏—â–∞–µ–º canvas
    if (canvasRef.current) {
      const canvas = canvasRef.current;
      const canvasCtx = canvas.getContext("2d");
      if (canvasCtx) {
        canvasCtx.fillStyle = "#f8fafc";
        canvasCtx.fillRect(0, 0, canvas.width, canvas.height);
      }
    }
  }, [canvasRef]);

  // –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è –≤–æ–ª–Ω—ã –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
  const drawRealTimeWave = useCallback(() => {
    if (!analyserRef.current || !canvasRef.current) {
      console.log("Missing analyser or canvas ref", {
        analyser: !!analyserRef.current,
        canvas: !!canvasRef.current,
      });
      return;
    }

    const canvas = canvasRef.current;
    const canvasCtx = canvas.getContext("2d");
    if (!canvasCtx) {
      console.log("Could not get canvas context");
      return;
    }

    console.log("Starting real-time wave visualization", {
      canvasSize: { width: canvas.width, height: canvas.height },
    });
    const analyser = analyserRef.current;
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    isAnimatingRef.current = true;

    const draw = () => {
      if (!isAnimatingRef.current) {
        // –û—á–∏—â–∞–µ–º canvas –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –∑–∞–ø–∏—Å–∏
        canvasCtx.fillStyle = "#ffffff";
        canvasCtx.fillRect(0, 0, canvas.width, canvas.height);
        return;
      }

      animationIdRef.current = requestAnimationFrame(draw);

      // –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–∏ (–ª—É—á—à–µ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏)
      analyser.getByteTimeDomainData(dataArray);

      // –û—á–∏—â–∞–µ–º –∫–∞–Ω–≤–∞—Å
      canvasCtx.fillStyle = "#ffffff";
      canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

      // –†–∏—Å—É–µ–º –≤–æ–ª–Ω—É –∫–∞–∫ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª–æ—Å–∫–∏ (–∫–∞–∫ –≤ WaveSurfer)
      const barWidth = 3;
      const barGap = 1;
      const totalBars = Math.floor(canvas.width / (barWidth + barGap));
      const step = Math.floor(bufferLength / totalBars);

      console.log("Drawing wave", {
        canvasSize: { width: canvas.width, height: canvas.height },
        totalBars,
        bufferLength,
        step,
      });

      let hasAudio = false;

      // –°–æ–∑–¥–∞–µ–º –º–∞—Å—Å–∏–≤ –≤—ã—Å–æ—Ç –¥–ª—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏
      const barHeights: number[] = [];

      // –°–Ω–∞—á–∞–ª–∞ –≤—ã—á–∏—Å–ª—è–µ–º –≤—Å–µ –≤—ã—Å–æ—Ç—ã
      for (let i = 0; i < totalBars; i++) {
        const dataIndex = i * step;
        const value = dataArray[dataIndex];

        // –î–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ç —Ü–µ–Ω—Ç—Ä–∞ (128)
        const normalizedValue = Math.abs(value - 128) / 128.0;

        if (normalizedValue > 0.01) hasAudio = true;

        // –°–æ–∑–¥–∞–µ–º –±–æ–ª–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—É—é –∏ –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
        const baseHeight = 4;
        const amplifiedValue = Math.pow(normalizedValue, 0.7) * 2.5;
        const barHeight = Math.max(
          baseHeight,
          amplifiedValue * canvas.height * 0.8
        );

        barHeights.push(barHeight);
      }

      // –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –∫ –≤—ã—Å–æ—Ç–∞–º –¥–ª—è –±–æ–ª–µ–µ –ø–ª–∞–≤–Ω—ã—Ö –ø–µ—Ä–µ—Ö–æ–¥–æ–≤
      const smoothedHeights: number[] = [];
      for (let i = 0; i < barHeights.length; i++) {
        let sum = barHeights[i];
        let count = 1;

        // –£—Å—Ä–µ–¥–Ω—è–µ–º —Å —Å–æ—Å–µ–¥–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏
        if (i > 0) {
          sum += barHeights[i - 1];
          count++;
        }
        if (i < barHeights.length - 1) {
          sum += barHeights[i + 1];
          count++;
        }

        smoothedHeights.push(sum / count);
      }

      // –¢–µ–ø–µ—Ä—å —Ä–∏—Å—É–µ–º —Å –ø–ª–∞–≤–Ω—ã–º–∏ –≤—ã—Å–æ—Ç–∞–º–∏
      for (let i = 0; i < totalBars; i++) {
        const barHeight = smoothedHeights[i];

        const x = i * (barWidth + barGap);
        const y = (canvas.height - barHeight) / 2;

        // –°–æ–∑–¥–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∞ (—Å–∏–Ω–∏–µ —Ç–æ–Ω–∞ –¥–ª—è –±–µ–ª–æ–π —Ç–µ–º—ã)
        const gradient = canvasCtx.createLinearGradient(0, y, 0, y + barHeight);
        gradient.addColorStop(0, "#3B82F6");
        gradient.addColorStop(0.5, "#1D4ED8");
        gradient.addColorStop(1, "#1E40AF");

        canvasCtx.fillStyle = gradient;

        // –†–∏—Å—É–µ–º –ø–æ–ª–æ—Å–∫—É —Å –∑–∞–∫—Ä—É–≥–ª–µ–Ω–Ω—ã–º–∏ —É–≥–ª–∞–º–∏ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)
        canvasCtx.fillStyle = gradient;

        // –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        canvasCtx.fillRect(x, y, barWidth, barHeight);
      }

      // –õ–æ–≥–∏—Ä—É–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ
      if (hasAudio) {
        console.log("Audio activity detected", { hasAudio, totalBars });
      }
    };

    // –ù–∞—á–∏–Ω–∞–µ–º —Ü–∏–∫–ª –∞–Ω–∏–º–∞—Ü–∏–∏
    draw();
  }, [canvasRef]);

  // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
  const startVisualization = useCallback(async (): Promise<boolean> => {
    try {
      console.log("Starting audio visualization initialization...");

      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
      });

      console.log("Got media stream", stream);
      streamRef.current = stream;

      const audioContext = new (window.AudioContext ||
        (window as typeof window & { webkitAudioContext: typeof AudioContext })
          .webkitAudioContext)();
      audioContextRef.current = audioContext;
      console.log("Created audio context", audioContext);

      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 2048;
      analyser.smoothingTimeConstant = 0.8;
      analyser.minDecibels = -90;
      analyser.maxDecibels = -10;
      analyserRef.current = analyser;
      console.log("Created analyser", analyser);

      const source = audioContext.createMediaStreamSource(stream);
      source.connect(analyser);
      console.log("Connected audio source to analyser");

      // –°–æ–∑–¥–∞–µ–º MediaRecorder –¥–ª—è –∑–∞–ø–∏—Å–∏
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;

      const audioChunks: Blob[] = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunks.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        const audioBlob = new Blob(audioChunks, { type: "audio/wav" });
        if (onRecordingStop) {
          onRecordingStop(audioBlob);
        }
        audioChunks.length = 0;
      };

      // –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å
      mediaRecorder.start();
      console.log("Started media recorder");

      // –ó–∞–ø—É—Å–∫–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
      console.log("Starting visualization with canvas:", canvasRef.current);
      drawRealTimeWave();

      return true;
    } catch (error) {
      console.error("Failed to initialize audio visualization:", error);
      return false;
    }
  }, [drawRealTimeWave, onRecordingStop, canvasRef]);

  // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –∑–∞–ø–∏—Å–∏
  const stopVisualization = useCallback(() => {
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–Ω–∏–º–∞—Ü–∏—é
    stopAnimation();

    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å
    if (
      mediaRecorderRef.current &&
      mediaRecorderRef.current.state !== "inactive"
    ) {
      mediaRecorderRef.current.stop();
    }

    // –û—á–∏—â–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
    if (streamRef.current) {
      streamRef.current.getTracks().forEach((track) => track.stop());
      streamRef.current = null;
    }

    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    mediaRecorderRef.current = null;
    analyserRef.current = null;
  }, [stopAnimation]);

  // Cleanup –ø—Ä–∏ —Ä–∞–∑–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
  useEffect(() => {
    return () => {
      stopVisualization();
    };
  }, [stopVisualization]);

  return {
    startVisualization,
    stopVisualization,
    isAnimating: isAnimatingRef.current,
  };
};
